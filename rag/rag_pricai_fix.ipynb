{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import pandas as pd\n",
    "# from datasets import Dataset\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Load environment\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaniagalih/pricai/DREAM_CS-TUTORIAL-PRICAI-2024/pricai_venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# define llm\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://pricai.org/2024/\n",
      "Title: HOME\n",
      "Paragraphs:\n",
      "\n",
      "The Pacific Rim International Conference on Artificial Intelligence (PRICAI) is an annual international event which concentrates on AI theories, technologies and their applications in the areas of scientific, social, and economic importance for countries in the Pacific Rim. In the past, the conferences have been held in Nagoya (1990), Seoul (1992), Beijing (1994), Cairns (1996), Singapore (1998), Melbourne (2000), Tokyo (2002), Auckland (2004), Guilin (2006), Hanoi (2008), Daegu (2010), Kuching (2012), Gold Coast (2014), Phuket (2016), Nanjing (2018), Fiji (2019), Yokohama (2020, online), Hanoi (2021, online), Shanghai (2022, hybrid) and Jakarta (2023, hybrid).\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def scrape_page_content(url):\n",
    "    async with async_playwright() as p:\n",
    "        # Launch a browser and open a new page\n",
    "        browser = await p.chromium.launch()\n",
    "        page = await browser.new_page()\n",
    "        # Navigate to the given URL\n",
    "        await page.goto(url)\n",
    "        # Retrieve the page content\n",
    "        html = await page.content()\n",
    "        # Close the browser\n",
    "        await browser.close()\n",
    "\n",
    "        # Parse the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # Get the title of the page\n",
    "        title = soup.title.string if soup.title else 'No Title'\n",
    "        # Extract all paragraph texts\n",
    "        paragraphs = [p.get_text() for p in soup.find_all('p')]\n",
    "\n",
    "        return {\n",
    "            'url': url,\n",
    "            'title': title,\n",
    "            'paragraphs': paragraphs\n",
    "        }\n",
    "\n",
    "# Usage\n",
    "url_to_scrape = \"https://pricai.org/2024/\"\n",
    "\n",
    "# Run the function \n",
    "scraped_data = await scrape_page_content(url_to_scrape)\n",
    "\n",
    "# Print the scraped data\n",
    "print(f\"URL: {scraped_data['url']}\")\n",
    "print(f\"Title: {scraped_data['title']}\")\n",
    "print(\"Paragraphs:\")\n",
    "for paragraph in scraped_data['paragraphs'][:2]:  \n",
    "    print(paragraph)\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Ensure scraped_data is in a list to make this compatible with the list comprehension\n",
    "scraped_data = [scraped_data] if isinstance(scraped_data, dict) else scraped_data\n",
    "\n",
    "# Populate the link_content_map while creating the documents\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\" \".join(data['paragraphs']),\n",
    "        metadata={\"url\": data['url'], \"title\": data['title']}\n",
    "    )\n",
    "    for data in scraped_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "chunk_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db_chroma = Chroma.from_documents(chunk_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "retriever = db_chroma.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the Chroma Vector Database:\n",
      "Link                                                                                                 Generated from Web Scraping                                                                                                                                                                             \n",
      "============================================================================================================================================================================================================================================================================================================\n",
      "https://pricai.org/2024/                                                                             The Pacific Rim International Conference on Artificial Intelligence (PRICAI) is an annual international event which concentrates on AI theories, technologies and their applications in the areas of ...\n"
     ]
    }
   ],
   "source": [
    "# Function to print contents of chunk_docs\n",
    "def print_stored_documents(chunk_docs, limit=20):\n",
    "    print(\"Contents of the Chroma Vector Database:\")\n",
    "    print(\"{:<100} {:<200}\".format(\"Link\", \"Generated from Web Scraping\"))  # Header\n",
    "    print(\"=\" * 300)  # Separator\n",
    "\n",
    "    # Iterate through the chunked documents and print their content\n",
    "    for idx, doc in enumerate(chunk_docs):\n",
    "        if idx >= limit:  # Limit to the first 'limit' entries\n",
    "            break\n",
    "\n",
    "        # Extract URL and content from metadata and page content\n",
    "        url = doc.metadata.get(\"url\", \"No URL\")\n",
    "        content = doc.page_content  # The content generated from web scraping\n",
    "\n",
    "        # Print the URL and the content\n",
    "        print(\"{:<100} {:<200}\".format(url, content[:197] + '...' if len(content) > 200 else content))\n",
    "\n",
    "# Call the function to print the stored documents\n",
    "print_stored_documents(chunk_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# define prompt template -> downgrade \n",
    "answer_prompt = \"\"\"\n",
    "You are an AI assistant here to answer questions about PRICAI 2024. Use only the provided context to answer the question accurately. If there is no relevant information in the context, respond with \"I'm not sure about that; it's outside my available information.\"\n",
    "\n",
    "Guidelines:\n",
    "- Answer only if the context provides relevant information.\n",
    "- Respond \"I'm not sure about that; it's outside my available information\" for unrelated or unsupported questions.\n",
    "- Avoid answering questions about unrelated topics, brands, or products.\n",
    "\n",
    "Steps:\n",
    "1. Review the userâ€™s question and the context provided.\n",
    "2. Verify if the question relates to PRICAI 2024.\n",
    "3. If relevant information is available, answer the question.\n",
    "4. If helpful, provide links from the context in the response.\n",
    "\n",
    "Question: {messages}\n",
    "Answer: {context}\n",
    "\n",
    "Give a clear, organized answer in bullet points if necessary. Make the response easy to read and focused only on relevant information.\n",
    "\"\"\"\n",
    "\n",
    "# Chat prompt template\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", answer_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, question_answering_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Function to query the vector store and generate a response\n",
    "def generate_response(query):\n",
    "    # Retrieve similar documents\n",
    "    docs = retriever.get_relevant_documents(query, k=10)\n",
    "\n",
    "    # Use the documents as context for the LLM\n",
    "    response = document_chain.invoke(\n",
    "        {\n",
    "            \"context\": docs,\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=query)\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- PRICAI 2024 will be held in Kyoto, Japan.\n",
      "- It is an in-person event.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "query = \"where is Pricai converence held?\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To attend the PRICAI 2024 conference, you can prepare the following:\n",
      "\n",
      "- **Research Papers**: If you are a researcher, consider submitting a technical paper on substantial, original, and unpublished research in all aspects of Artificial Intelligence.\n",
      "- **Networking**: Be ready to engage with researchers, practitioners, educators, and users in AI for in-depth intellectual exchanges and research cooperation.\n",
      "- **Travel Arrangements**: Since PRICAI 2024 will be held in person in Kyoto, Japan, prepare your travel plans, including flights, accommodation, and any necessary visas.\n",
      "- **Conference Materials**: Gather any materials you might need for presentations or discussions, such as business cards and a notebook for taking notes.\n",
      "\n",
      "Keep an eye on any updates or specific requirements from the conference organizers.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "query = \"what can I prepare to attent the Pricai conference?\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **PRICAI**: The Pacific Rim International Conference on Artificial Intelligence (PRICAI) is an annual international event focused on AI theories, technologies, and applications, particularly in the Pacific Rim region.\n",
      "\n",
      "- **Purpose of the Event**: The conference is organized every year to:\n",
      "  - Facilitate discussions on AI research and development.\n",
      "  - Encourage exchanges of ideas among researchers, practitioners, educators, and users in the AI field.\n",
      "  - Foster research cooperation and professional development.\n",
      "\n",
      "- **Expectations from the Event**:\n",
      "  - To serve as a platform for presenting substantial, original, and unpublished research in AI.\n",
      "  - To bring together AI communities for in-depth intellectual exchanges.\n",
      "  - To promote advancements in areas of scientific, social, and economic importance.\n",
      "\n",
      "PRICAI 2024 will be held in person in Kyoto, Japan, and will be co-located with PRIMA2024.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "query = \"What is pricai, and why they make an event every year, what they expected from that event?\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure about that; it's outside my available information.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "query = \"I want to cook pisang goreng, please make the step and recipe\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAG can't answer the question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure about that; it's outside my available information.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "query = \"Who is Prof. Bo An, Nanyang Technological University, Singapore also what his contribution in Pricai 2024?\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure about that; it's outside my available information.\n"
     ]
    }
   ],
   "source": [
    "# query -> Can't answer\n",
    "query = \"when last call for the proposal and paper submited?\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure about that; it's outside my available information.\n"
     ]
    }
   ],
   "source": [
    "# query -> Can't answer\n",
    "query = \"give me the schedule for pricai 2024\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure about that; it's outside my available information.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "query = \"List down topic that will present in PRICAI 2024\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure about that; it's outside my available information.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "query = \"is there any topics that explain about synthetic data\"\n",
    "response = generate_response(query)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pricai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
